Synchronisation properties
Safety – There is no way for two threads to be in the critical section concurrently, so they cannot interfere with each other. This property is also called mutual exclusion.
Liveness – If no thread is in the critical section and at least one tries to enter, then one of the threads will be able to enter. This property is also called progress.
Fairness – Assuming neither thread can remain in the critical section indefinitely, if a thread attempts to enter the critical section, it will eventually do so. This property is also called bounded waiting.


Locks

One of the fundamental synchronisation primities to eliminate the race condition in the crtitical section.
it can be callled mutex lock 
it provide the mutual exclusing access to the critical section
That is, once a thread acquires a lock and enters a critical section, no other thread can also enter the critical section until the first thread completes its work

Locks have the following key features:
  Mutual exclusion: A lock is initially considered to be unlocked. Only one thread can acquire the lock at a time. Once a lock has been acquired by one thread, no other lock can acquire it until it has been released.
  Non-preemption: If a thread acquires a lock, no other thread can take it away. The thread that has acquired the lock must voluntarily release it.
  Atomic acquire and release operations: The implementation of these operations guarantee their executions to be free of race conditions. If two threads both try to acquire a lock at the same time, either one succeeds and one fails, or both fail (if the lock was previously acquired). Similarly, when a thread releases a lock that it has acquired, this operation cannot fail due to interrupts or other exceptional control flow.
  Blocking acquire operations: If a thread tries to acquire a lock that is currently being held by another thread, the current request to acquire the lock blocks and is added to a request queue for the lock. When a thread that holds a lock with pending requests releases it, exactly one of the waiting threads will become unblocked and acquire it.

Operation should be automic - it means it should not be interepted by any other thread or with any exception

POSIX Mutex

Operations
init, destroy, lock, trylock, unlock

Spinlocks
Traditional locks also suffer from one very subtle (but occasionally significant) performance penalty: context switches. The penalty arises from the fact that operations to acquire the lock can block the current thread if the lock is not available. At this point, the kernel must select another thread to run (takes time), save the current thread’s registers (takes time), possibly flush one or more levels of the cache (takes time), possibly switch virtual memory spaces (takes time), and so on.
As a rough average estimate, context switches on modern systems take around 2000 ns. In many cases, those time penalties are expected and unavoidable. But consider a case where thread A is in possession of a lock and is almost ready to release it. If thread B is running and attempts to acquire the lock, it would have to wait at least 4000 ns for the kernel to switch from thread B to A and then back from thread A to B. However, what if B’s execution could be delayed for 10 ns, during which time A releases the lock? That is, by waiting 10 ns, B could avoid almost 4000 ns of unnecessary context. If this happens often enough, the system could experience a significant speedup.
In traditional uniprocessing systems, this argument is nonsensical. If one thread is running, then it is impossible for another thread to be releasing the lock at the same time. The reason is that uniprocessing systems could only execute one instruction (i.e., one thread) at a time. However, in multiprocessing systems, including multicore, there is true parallelism happening. That is, it is possible for threads A and B to be running—and working with the lock—at the exact same moment in time.
To exploit this advantage in parallel execution, POSIX (like other modern thread libraries) include a newer variation on locks called spinlocks. A spinlock behaves similarly to a traditional lock with one exception: Instead of blocking if the lock is owned by another thread, the spinlock stays in a loop that keeps trying. If the lock becomes immediately available, the thread can then continue without the penalty of a context switch. The POSIX interface for spinlocks is virtually identical to the one for mutexes. The difference is primarily in the internal implementation.
Given that spinlocks can benefit from avoiding unnecessary context switches, it may seem that they are inherently superior to mutexes. However, this is not the case, and mutexes often perform better. Note that spinlocks only benefit when waiting takes less time than executing a context switch. In the example above, we assumed that the thread only needed to wait 10 ns for the lock to become available.
However, if the lock’s owner is performing a complex and long-running operation, the thread using the spinlock will consume the CPU time for the rest of its quantum, which is typically on the order of 100 ms (i.e., 100,000,000 ns). That is, if the lock does not become immediately available, the thread will waste millions of clock cycles in an attempt to save thousands. Clearly, this would be a horrible trade-off!
The choice of spinlocks vs. traditional mutexes ultimately comes down to the typical duration of the critical sections. If all of the critical sections are short in duration, then spinlocks are likely to provide superior performance, as there is an increased likelihood that the lock’s holder will be releasing it soon. If long critical sections are common, then mutexes are preferable to avoid the wasted CPU time that comes from spinlocks’ busy waiting.

